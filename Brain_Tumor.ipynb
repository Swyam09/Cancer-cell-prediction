{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Brain Tumor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGSqZ6pP7lK_"
      },
      "source": [
        "#Importing needed python modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings as wr\n",
        "#Ignoring warnings\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "wr.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N90bAHUN70p6"
      },
      "source": [
        "#Loading data into dataframe(df)\n",
        "df=pd.read_csv('Brain_tumor_data.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt7MU1LT8FY3",
        "outputId": "c34116d0-8e87-4b7f-a53e-8d7af7fab921"
      },
      "source": [
        "print(df.head(10))#Print all data of top 10 rows\n",
        "print(df.shape)#Print the row and clumn count of the data\n",
        "print(df.isna().sum())#Print all columns with empty data along with sum of empty data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Target       Mean     Variance  ...      SSIM       MSE        DC\n",
            "0       1  23.448517  2538.985627  ...  0.777011  0.171163  0.303989\n",
            "1       1   4.398331   834.853030  ...  0.977953  0.009913  0.839019\n",
            "2       1   3.244263   642.059167  ...  0.985362  0.006372  0.849775\n",
            "3       0   8.511353  1126.214187  ...  0.881015  0.068437  0.000000\n",
            "4       0  21.000793  2235.316978  ...  0.766308  0.184878  0.000000\n",
            "5       0  11.350555   998.972243  ...  0.794881  0.128889  0.000000\n",
            "6       1   0.405136    68.378718  ...  0.985175  0.007830  0.410458\n",
            "7       1   5.955872   937.438650  ...  0.981891  0.007708  0.914484\n",
            "8       1   6.184021   895.196827  ...  0.983963  0.005295  0.945252\n",
            "9       1   0.260590    52.284893  ...  0.982749  0.012448  0.191657\n",
            "\n",
            "[10 rows x 18 columns]\n",
            "(1275, 18)\n",
            "Target                0\n",
            "Mean                  0\n",
            "Variance              0\n",
            "Standard Deviation    0\n",
            "Entropy               0\n",
            "Skewness              0\n",
            "Kurtosis              0\n",
            "Contrast              0\n",
            "Energy                0\n",
            "ASM                   0\n",
            "Homogeneity           0\n",
            "Dissimilarity         0\n",
            "Correlation           0\n",
            "Coarseness            0\n",
            "PSNR                  0\n",
            "SSIM                  0\n",
            "MSE                   0\n",
            "DC                    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLSmfMPH8T7o"
      },
      "source": [
        "df=df.dropna(axis=1)#Drop the column with empty data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "japfKGIf9OuE"
      },
      "source": [
        "#Encoding first column\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_X=LabelEncoder()\n",
        "df.iloc[:,0]=labelencoder_X.fit_transform(df.iloc[:,0].values)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EmzFZXC9U26"
      },
      "source": [
        "#Splitting data for dependence\n",
        "X=df.iloc[:,1:].values\n",
        "Y=df.iloc[:,0].values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGXzpQb1901j"
      },
      "source": [
        "#Train-Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm_hoLgs93Rm"
      },
      "source": [
        "#Standard scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.fit_transform(X_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P151nfB6-Z9H"
      },
      "source": [
        "#Importing algorithm libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoLOY9KF96rX"
      },
      "source": [
        "#Function for  different models\n",
        "def models(X_train,Y_train):\n",
        "\n",
        "    #Logistic regression\n",
        "    log=LogisticRegression(random_state=0)\n",
        "    log.fit(X_train,Y_train)\n",
        "\n",
        "    #Decision tree\n",
        "    tree=DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
        "    tree.fit(X_train,Y_train)\n",
        "\n",
        "    #Random forest classifier\n",
        "    forest=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\n",
        "    forest.fit(X_train,Y_train)\n",
        "\n",
        "    #GaussianNB\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train,Y_train)\n",
        "\n",
        "    #Printing accuracy\n",
        "    print(\"Logistic regression:\",log.score(X_train,Y_train))\n",
        "    print(\"Decision Tree:\",tree.score(X_train,Y_train))\n",
        "    print(\"Random Forest:\",forest.score(X_train,Y_train))\n",
        "    print(\"GaussianNB:\",gnb.score(X_train,Y_train))\n",
        "    return log,tree,forest,gnb"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ox7IZET9_EM",
        "outputId": "e8d378f5-0731-4bad-bdea-712f7483523a"
      },
      "source": [
        "#Testing Function for all models\n",
        "model=models(X_train,Y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic regression: 0.9738493723849372\n",
            "Decision Tree: 1.0\n",
            "Random Forest: 1.0\n",
            "GaussianNB: 0.9801255230125523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdNvX5Wi-Eew",
        "outputId": "089e8f2c-c876-4760-ca0b-053bf80054df"
      },
      "source": [
        "#Metrics of the models\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "for i in range(len(model)):\n",
        "    print(\"\\nModel:\",i+1)\n",
        "    print(\"Classification Report\")\n",
        "    print(classification_report(Y_test,model[i].predict(X_test)))\n",
        "    print(\"Accuracy Score:\",accuracy_score(Y_test,model[i].predict(X_test)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model: 1\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.86      0.62        14\n",
            "           1       0.99      0.96      0.97       305\n",
            "\n",
            "    accuracy                           0.95       319\n",
            "   macro avg       0.74      0.91      0.80       319\n",
            "weighted avg       0.97      0.95      0.96       319\n",
            "\n",
            "Accuracy Score: 0.9529780564263323\n",
            "\n",
            "Model: 2\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.93      0.59        14\n",
            "           1       1.00      0.94      0.97       305\n",
            "\n",
            "    accuracy                           0.94       319\n",
            "   macro avg       0.71      0.94      0.78       319\n",
            "weighted avg       0.97      0.94      0.95       319\n",
            "\n",
            "Accuracy Score: 0.9435736677115988\n",
            "\n",
            "Model: 3\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      1.00      0.64        14\n",
            "           1       1.00      0.95      0.97       305\n",
            "\n",
            "    accuracy                           0.95       319\n",
            "   macro avg       0.73      0.97      0.80       319\n",
            "weighted avg       0.98      0.95      0.96       319\n",
            "\n",
            "Accuracy Score: 0.9498432601880877\n",
            "\n",
            "Model: 4\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        14\n",
            "           1       0.96      1.00      0.98       305\n",
            "\n",
            "    accuracy                           0.96       319\n",
            "   macro avg       0.48      0.50      0.49       319\n",
            "weighted avg       0.91      0.96      0.93       319\n",
            "\n",
            "Accuracy Score: 0.9561128526645768\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}