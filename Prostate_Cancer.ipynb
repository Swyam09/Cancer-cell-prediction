{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prostate Cancer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L00Btw1lAVoQ"
      },
      "source": [
        "#Importing needed python modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings as wr\n",
        "#Ignoring warnings\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "wr.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9xEpCcKAlOl"
      },
      "source": [
        "#Loading data into dataframe(df)\n",
        "df=pd.read_csv('Prostate_cancer_data.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmtVY4RoAuGv",
        "outputId": "f1fa5cbd-9d4c-4b88-e598-d4f57c0ef086"
      },
      "source": [
        "print(df.head(10))#Print all data of top 10 rows\n",
        "print(df.shape)#Print the row and clumn count of the data\n",
        "print(df.isna().sum())#Print all columns with empty data along with sum of empty data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id diagnosis_result  radius  ...  compactness  symmetry  fractal_dimension\n",
            "0   1                M      23  ...        0.278     0.242              0.079\n",
            "1   2                B       9  ...        0.079     0.181              0.057\n",
            "2   3                M      21  ...        0.160     0.207              0.060\n",
            "3   4                M      14  ...        0.284     0.260              0.097\n",
            "4   5                M       9  ...        0.133     0.181              0.059\n",
            "5   6                B      25  ...        0.170     0.209              0.076\n",
            "6   7                M      16  ...        0.109     0.179              0.057\n",
            "7   8                M      15  ...        0.165     0.220              0.075\n",
            "8   9                M      19  ...        0.193     0.235              0.074\n",
            "9  10                M      25  ...        0.240     0.203              0.082\n",
            "\n",
            "[10 rows x 10 columns]\n",
            "(100, 10)\n",
            "id                   0\n",
            "diagnosis_result     0\n",
            "radius               0\n",
            "texture              0\n",
            "perimeter            0\n",
            "area                 0\n",
            "smoothness           0\n",
            "compactness          0\n",
            "symmetry             0\n",
            "fractal_dimension    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rL5CFjVAwsY"
      },
      "source": [
        "df=df.dropna(axis=1)#Drop the column with empty data\n",
        "df=df.drop(['id'],axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CDLEGJ6A1q9"
      },
      "source": [
        "#Encoding first column\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_X=LabelEncoder()#Calling LabelEncoder\n",
        "df.iloc[:,0]=labelencoder_X.fit_transform(df.iloc[:,0].values)#Encoding the values of diagnosis column to values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzX5kbgzBPmM"
      },
      "source": [
        "#Splitting data for dependence\n",
        "X=df.iloc[:,1:].values#Features of cancerous and non cancerous patients\n",
        "Y=df.iloc[:,0].values#Whether patient has cancer or not"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u41tv0pBRw6"
      },
      "source": [
        "#Train-Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0Exzn6EBUIf"
      },
      "source": [
        "#Standard scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)#Scaling X_train\n",
        "X_test=sc.fit_transform(X_test)#Scaling X_test"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrP-MdGABWZG"
      },
      "source": [
        "#Importing algorithm libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WPzz7K4BX__"
      },
      "source": [
        "#Function for  different models\n",
        "def models(X_train,Y_train):\n",
        "\n",
        "    #Logistic regression\n",
        "    log=LogisticRegression(random_state=0)\n",
        "    log.fit(X_train,Y_train)\n",
        "\n",
        "    #Decision tree\n",
        "    tree=DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
        "    tree.fit(X_train,Y_train)\n",
        "\n",
        "    #Random forest classifier\n",
        "    forest=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\n",
        "    forest.fit(X_train,Y_train)\n",
        "\n",
        "    #GaussianNB\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train,Y_train)\n",
        "\n",
        "    #Printing accuracy\n",
        "    print(\"Logistic regression:\",log.score(X_train,Y_train))\n",
        "    print(\"Decision Tree:\",tree.score(X_train,Y_train))\n",
        "    print(\"Random Forest:\",forest.score(X_train,Y_train))\n",
        "    print(\"GaussianNB:\",gnb.score(X_train,Y_train))\n",
        "    return log,tree,forest,gnb"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ira6ae8KBaHX",
        "outputId": "da265b0d-7fdf-4abd-d959-81ccdcdaec00"
      },
      "source": [
        "#Testing Function for all models\n",
        "print(\"Accuracy\")\n",
        "model=models(X_train,Y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy\n",
            "Logistic regression: 0.88\n",
            "Decision Tree: 1.0\n",
            "Random Forest: 0.9733333333333334\n",
            "GaussianNB: 0.8666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQr8ZRufBcEu",
        "outputId": "b8fcd229-ac37-486a-c9a5-ca9c793541d5"
      },
      "source": [
        "#Metrics of the models\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "for i in range(len(model)):\n",
        "    print(\"\\nModel:\",i+1)\n",
        "    print(\"Classification Report\")\n",
        "    print(classification_report(Y_test,model[i].predict(X_test)))\n",
        "    print(\"Accuracy Score:\",accuracy_score(Y_test,model[i].predict(X_test)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model: 1\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.60      0.71        10\n",
            "           1       0.78      0.93      0.85        15\n",
            "\n",
            "    accuracy                           0.80        25\n",
            "   macro avg       0.82      0.77      0.78        25\n",
            "weighted avg       0.81      0.80      0.79        25\n",
            "\n",
            "Accuracy Score: 0.8\n",
            "\n",
            "Model: 2\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.50      0.56        10\n",
            "           1       0.71      0.80      0.75        15\n",
            "\n",
            "    accuracy                           0.68        25\n",
            "   macro avg       0.67      0.65      0.65        25\n",
            "weighted avg       0.67      0.68      0.67        25\n",
            "\n",
            "Accuracy Score: 0.68\n",
            "\n",
            "Model: 3\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86        10\n",
            "           1       0.93      0.87      0.90        15\n",
            "\n",
            "    accuracy                           0.88        25\n",
            "   macro avg       0.87      0.88      0.88        25\n",
            "weighted avg       0.88      0.88      0.88        25\n",
            "\n",
            "Accuracy Score: 0.88\n",
            "\n",
            "Model: 4\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      1.00      0.77        10\n",
            "           1       1.00      0.60      0.75        15\n",
            "\n",
            "    accuracy                           0.76        25\n",
            "   macro avg       0.81      0.80      0.76        25\n",
            "weighted avg       0.85      0.76      0.76        25\n",
            "\n",
            "Accuracy Score: 0.76\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}